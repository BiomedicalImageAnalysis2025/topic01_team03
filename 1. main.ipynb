{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5795aabd",
   "metadata": {},
   "source": [
    "# Bioinformatik Projekt: Otsu Thresholding und Bimodalit√§ts-Verbesserung\n",
    "\n",
    "Dieses Jupyter Notebook demonstriert die Funktionsweise unseres Bildverarbeitungsprojekts, bei dem wir verschiedene Varianten des Otsu-Verfahrens zur automatischen Schwellenwertbestimmung auf Mikroskopbilder anwenden und evaluieren.\n",
    "\n",
    "## üîß Preprocessing-Modul: Bimodalit√§tsverst√§rkung\n",
    "\n",
    "Die Funktion `enhance_bimodality` verbessert die Trennung zwischen Vorder- und Hintergrundintensit√§ten. Sie kombiniert:\n",
    "- adaptive Gamma-Korrektur (abh√§ngig von der mittleren Helligkeit)\n",
    "- Histogramm-Equalisierung √ºber die CDF\n",
    "\n",
    "Dies erleichtert die sp√§tere Segmentierung mittels Otsu-Schwellenwerten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40dc99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# src/bimodality_enhancement.py\n",
    "import numpy as np\n",
    "\n",
    "def enhance_bimodality(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Enhances the bimodality of a grayscale image by applying adaptive gamma correction\n",
    "    followed by histogram equalization.\n",
    "    \"\"\"\n",
    "    if img.dtype != np.float32 and img.max() > 1.0:\n",
    "        img = img / 255.0\n",
    "\n",
    "    mean_intensity = np.mean(img)\n",
    "    gamma = 3.0 if mean_intensity >= 0.5 else 0.5\n",
    "    img_gamma = np.power(img, gamma)\n",
    "\n",
    "    img_8bit = (img_gamma * 255).astype(np.uint8)\n",
    "    hist, _ = np.histogram(img_8bit.flatten(), bins=256, range=[0, 256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * 255 / cdf[-1]\n",
    "\n",
    "    img_eq = cdf_normalized[img_8bit].astype(np.uint8)\n",
    "    return img_eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e91ddb",
   "metadata": {},
   "source": [
    "## üìâ Otsu Thresholding (Skimage-kompatibel)\n",
    "\n",
    "Der folgende Abschnitt zeigt eine eigene Reimplementierung des Otsu-Verfahrens zur globalen Schwellenwertbestimmung. Die Funktion `otsu_threshold_skimage_like` imitiert exakt das Verhalten von `skimage.filters.threshold_otsu`, inklusive Histogramm-Normalisierung, Schwellenwertberechnung und R√ºckprojektion auf den Originalwertebereich.\n",
    "\n",
    "- `custom_histogram` sorgt f√ºr kompatible Histogramme bei beliebigen Intensit√§tsbereichen.\n",
    "- Das Verfahren maximiert die Varianz zwischen zwei Klassen (Hintergrund vs. Objekt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98c7a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# src/Complete_Otsu_Global.py\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def custom_histogram(image: np.ndarray, nbins: int = 256) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    img_min, img_max = image.min(), image.max()\n",
    "    image_scaled = (image - img_min) / (img_max - img_min) * 255\n",
    "    hist, bin_edges = np.histogram(image_scaled.ravel(), bins=nbins, range=(0, 255))\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    return hist, bin_centers\n",
    "\n",
    "def otsu_threshold_skimage_like(image: np.ndarray) -> float:\n",
    "    hist, bin_centers = custom_histogram(image, nbins=256)\n",
    "    p = hist.astype(np.float64) / hist.sum()\n",
    "\n",
    "    omega0 = np.cumsum(p)\n",
    "    omega1 = np.cumsum(p[::-1])[::-1]\n",
    "    mu0 = np.cumsum(p * bin_centers)\n",
    "    mu1 = np.cumsum((p * bin_centers)[::-1])[::-1]\n",
    "\n",
    "    sigma_b_squared = (omega0[:-1] * omega1[1:] * (mu0[:-1] / omega0[:-1] - mu1[1:] / omega1[1:])**2)\n",
    "    t_idx = np.argmax(sigma_b_squared)\n",
    "    t_scaled = bin_centers[t_idx]\n",
    "\n",
    "    img_min, img_max = image.min(), image.max()\n",
    "    t_original = t_scaled / 255 * (img_max - img_min) + img_min\n",
    "    return t_original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a12e2e",
   "metadata": {},
   "source": [
    "## üìè Evaluation: Dice Score\n",
    "\n",
    "Zur quantitativen Bewertung unserer Segmentierungsergebnisse verwenden wir den **Dice Similarity Coefficient (DSC)**, der die √úberlappung zweier bin√§rer Masken misst. Ein Wert von:\n",
    "- `1.0` bedeutet perfekte √úbereinstimmung,\n",
    "- `0.0` bedeutet keinerlei √úberlappung.\n",
    "\n",
    "Die Funktion `dice_score` vergleicht dabei unser vorhergesagtes Bin√§rbild mit einem Ground-Truth-Maskenbild.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94f953",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# src/Dice_Score.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def dice_score(prediction: np.ndarray, ground_truth: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient (DSC) between two binary masks.\n",
    "    \"\"\"\n",
    "    if prediction.shape != ground_truth.shape:\n",
    "        raise ValueError(\"Prediction and ground truth images must have the same shape.\")\n",
    "\n",
    "    sum_prediction = np.sum(prediction)\n",
    "    sum_ground_truth = np.sum(ground_truth)\n",
    "    positive_overlap = np.sum(np.logical_and(prediction, ground_truth))\n",
    "\n",
    "    if sum_prediction + sum_ground_truth == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return 2 * positive_overlap / (sum_prediction + sum_ground_truth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654f1c2",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Bildauswahl und -einlesung\n",
    "\n",
    "Die Funktion `find_and_load_image` erm√∂glicht es, beliebige Beispielbilder rekursiv im Projektordner `data-git` zu finden und als Graustufenbild zu laden. Das Bild wird als `numpy.ndarray` zur√ºckgegeben und ist bereit zur Verarbeitung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0907b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# utility: Bild rekursiv finden und laden\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "def find_and_load_image(filename: str,\n",
    "                        data_root: str = \"data-git\",\n",
    "                        as_gray: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Findet und l√§dt ein Bild rekursiv aus dem data_root-Ordner.\n",
    "    \"\"\"\n",
    "    root = Path(data_root)\n",
    "    for candidate in root.rglob(filename):\n",
    "        return io.imread(str(candidate), as_gray=as_gray)\n",
    "    raise FileNotFoundError(f\"{filename!r} nicht gefunden unter {data_root!r}\")\n",
    "\n",
    "# Beispiel (ausf√ºhrbar nur im echten Projektverzeichnis):\n",
    "# img = find_and_load_image(\"t01.tif\")\n",
    "# print(\"Shape:\", img.shape, \"Min/Max:\", img.min(), img.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94910c22",
   "metadata": {},
   "source": [
    "## üìä Histogrammanalyse\n",
    "\n",
    "Zur Analyse der Intensit√§tsverteilung eines Bildes nutzen wir `compute_gray_histogram` und `plot_gray_histogram`. Diese Funktionen helfen, den Kontrast und die Bimodalit√§t zu beurteilen ‚Äî wichtige Voraussetzungen f√ºr eine effektive Otsu-Segmentierung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb461cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# src/gray_hist.py\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "\n",
    "def compute_gray_histogram(\n",
    "    image_source: Union[Path, str, np.ndarray],\n",
    "    bins: int = 256,\n",
    "    value_range: Tuple[int, int] = (0, 255)\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes histogram of grayscale values from image path or array.\n",
    "    \"\"\"\n",
    "    if isinstance(image_source, (Path, str)):\n",
    "        img = Image.open(str(image_source)).convert(\"L\")\n",
    "        arr = np.array(img)\n",
    "    elif isinstance(image_source, np.ndarray):\n",
    "        arr = image_source\n",
    "    else:\n",
    "        raise TypeError(\"Expected file path or NumPy array.\")\n",
    "\n",
    "    hist, bin_edges = np.histogram(arr.ravel(), bins=bins, range=value_range)\n",
    "    return hist, bin_edges\n",
    "\n",
    "def plot_gray_histogram(hist: np.ndarray, bin_edges: np.ndarray):\n",
    "    \"\"\"\n",
    "    Plots a grayscale histogram.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(bin_edges[:-1], hist, width=bin_edges[1] - bin_edges[0], align='edge')\n",
    "    plt.xlabel(\"Pixel intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Grayscale Histogram\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5611464",
   "metadata": {},
   "source": [
    "## üìÇ Laden der Datens√§tze\n",
    "\n",
    "Die folgenden Funktionen erm√∂glichen das strukturierte Laden von Bildern und zugeh√∂rigen Ground-Truth-Masken f√ºr verschiedene Datens√§tze:\n",
    "\n",
    "- `N2DH-GOWT1` (2D-HeLa-Zellen, .tif)\n",
    "- `N2DL-HeLa` (2D-HeLa-Zellen, .tif)\n",
    "- `NIH3T3` (Maus-Fibroblasten, .png)\n",
    "\n",
    "Alle Funktionen geben vier Listen zur√ºck:\n",
    "1. Bilder (`imgs`)\n",
    "2. Ground Truths (`gts`)\n",
    "3. Bildpfade (`img_paths`)\n",
    "4. GT-Pfade (`gt_paths`)\n",
    "\n",
    "So wird konsistente Zuordnung garantiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca42e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# utility: Dataset Loader\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "script_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "def load_n2dh_gowt1_images(base_path=None):\n",
    "    if base_path is None:\n",
    "        base_path = os.path.join(project_root, \"data-git\", \"N2DH-GOWT1\")\n",
    "    img_dir, gt_dir = os.path.join(base_path, \"img\"), os.path.join(base_path, \"gt\")\n",
    "    img_paths = sorted(glob(os.path.join(img_dir, \"*.tif\")))\n",
    "    gt_paths  = sorted(glob(os.path.join(gt_dir, \"*.tif\")))\n",
    "    imgs = [imread(p, as_gray=True) for p in img_paths]\n",
    "    gts  = [imread(p, as_gray=True) for p in gt_paths]\n",
    "    return imgs, gts, img_paths, gt_paths\n",
    "\n",
    "def load_n2dl_hela_images(base_path=None):\n",
    "    if base_path is None:\n",
    "        base_path = os.path.join(project_root, \"data-git\", \"N2DL-HeLa\")\n",
    "    img_dir, gt_dir = os.path.join(base_path, \"img\"), os.path.join(base_path, \"gt\")\n",
    "    img_paths = sorted(glob(os.path.join(img_dir, \"*.tif\")))\n",
    "    gt_paths  = sorted(glob(os.path.join(gt_dir, \"*.tif\")))\n",
    "    imgs = [imread(p, as_gray=True) for p in img_paths]\n",
    "    gts  = [imread(p, as_gray=True) for p in gt_paths]\n",
    "    return imgs, gts, img_paths, gt_paths\n",
    "\n",
    "def load_nih3t3_images(base_path=None):\n",
    "    if base_path is None:\n",
    "        base_path = os.path.join(project_root, \"data-git\", \"NIH3T3\")\n",
    "    img_dir, gt_dir = os.path.join(base_path, \"img\"), os.path.join(base_path, \"gt\")\n",
    "    img_paths = sorted(glob(os.path.join(img_dir, \"*.png\")))\n",
    "    gt_paths  = sorted(glob(os.path.join(gt_dir, \"*.png\")))\n",
    "    imgs = [imread(p, as_gray=True) for p in img_paths]\n",
    "    gts  = [imread(p, as_gray=True) for p in gt_paths]\n",
    "    return imgs, gts, img_paths, gt_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765a3b3",
   "metadata": {},
   "source": [
    "## üß† Lokales Otsu-Thresholding\n",
    "\n",
    "Im Gegensatz zur globalen Methode berechnet `local_otsu` f√ºr jedes Pixel einen **lokalen Schwellenwert**, basierend auf einem Fenster um den Pixel herum. Dies ist besonders n√ºtzlich bei Bildern mit ungleichm√§√üiger Ausleuchtung oder variabler Hintergrundintensit√§t.\n",
    "\n",
    "### Methode:\n",
    "- Gleitendes Fenster mit konfigurierbarem Radius (Standard: 15)\n",
    "- F√ºr jedes Fenster wird die Otsu-Schwelle mit unserer `otsu_threshold_skimage_like` Methode berechnet\n",
    "- Bild wird ‚Äûreflektierend‚Äú gepolstert, um Randverluste zu vermeiden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa4e34",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# src/local_otsu.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "script_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.Complete_Otsu_Global import otsu_threshold_skimage_like\n",
    "\n",
    "def local_otsu(image: np.ndarray, radius: int = 15) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes local Otsu threshold map using sliding window approach.\n",
    "    \"\"\"\n",
    "    H, W = image.shape\n",
    "    t_map = np.zeros((H, W), dtype=image.dtype)\n",
    "    pad = radius\n",
    "    padded = np.pad(image, pad, mode=\"reflect\")\n",
    "    w = 2 * radius + 1\n",
    "\n",
    "    for i in range(H):\n",
    "        if i % 50 == 0 or i == H - 1:\n",
    "            print(f\"Processing row {i+1}/{H}...\")\n",
    "        for j in range(W):\n",
    "            block = padded[i : i + w, j : j + w]\n",
    "            t = otsu_threshold_skimage_like(block)\n",
    "            t_map[i, j] = t\n",
    "\n",
    "    return t_map\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
