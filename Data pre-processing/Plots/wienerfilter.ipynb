{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b3a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna-0.png            Dice = 0.8944\n",
      "dna-1.png            Dice = 0.8845\n",
      "dna-26.png           Dice = 0.8134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 223\u001b[39m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m ! Kein Ground-Truth für \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ! überspringe …\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m score = \u001b[43mprocess_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m dice_scores_NIH3T3.append(score)\n\u001b[32m    225\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_file.name\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Dice = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 190\u001b[39m, in \u001b[36mprocess_single\u001b[39m\u001b[34m(img_path, gt_path)\u001b[39m\n\u001b[32m    187\u001b[39m gt  = \u001b[32m1\u001b[39m - (((gt / gt.max()) * \u001b[32m255\u001b[39m).astype(np.uint8) == \u001b[32m0\u001b[39m)         \n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Wiener fitler, background estimation and removal\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m img_filtered = img_scaled - \u001b[43mlocal_wiener_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m201\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Otsu\u001b[39;00m\n\u001b[32m    193\u001b[39m binary1 = apply_global_otsu(img_filtered)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mlocal_wiener_filter\u001b[39m\u001b[34m(image, window_size, noise_variance)\u001b[39m\n\u001b[32m     37\u001b[39m window = img_padded[i:i+window_size, j:j+window_size]\n\u001b[32m     38\u001b[39m local_mean = window.mean()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m local_var = \u001b[43mwindow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Compute Wiener filter response\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_var > noise_variance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/_methods.py:191\u001b[39m, in \u001b[36m_var\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    186\u001b[39m         arrmean = arrmean / rcount\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m x = \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43marrmean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr.dtype.type, (nt.floating, nt.integer)):\n\u001b[32m    194\u001b[39m     x = um.multiply(x, x, out=x)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.image import imread\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "from typing import Union, Tuple\n",
    "\n",
    "#------ALL FUNCTIONS NEEDED------\n",
    "\n",
    "\n",
    "# Wiener filter\n",
    "def local_wiener_filter(image, window_size=5, noise_variance=None):\n",
    "    \"\"\"\n",
    "    Apply a local adaptive Wiener filter to a grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D numpy array of the grayscale image.\n",
    "    - window_size: size of the square window (odd integer).\n",
    "    - noise_variance: estimated variance of the noise; if None, estimate globally.\n",
    "\n",
    "    Returns:\n",
    "    - filtered: the Wiener-filtered image as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    # Pad the image to handle borders\n",
    "    pad = window_size // 2\n",
    "    img_padded = np.pad(image, pad, mode='reflect')\n",
    "\n",
    "    # Estimate global noise variance if not provided\n",
    "    if noise_variance is None:\n",
    "        noise_variance = np.var(image - np.mean(image))\n",
    "\n",
    "    filtered = np.zeros_like(image)\n",
    "    # Slide window over image\n",
    "    for i in range(filtered.shape[0]):\n",
    "        for j in range(filtered.shape[1]):\n",
    "            window = img_padded[i:i+window_size, j:j+window_size]\n",
    "            local_mean = window.mean()\n",
    "            local_var = window.var()\n",
    "            # Compute Wiener filter response\n",
    "            if local_var > noise_variance:\n",
    "                filtered[i, j] = local_mean + (local_var - noise_variance) / local_var * (image[i, j] - local_mean)\n",
    "            else:\n",
    "                filtered[i, j] = local_mean\n",
    "\n",
    "    f = filtered\n",
    "    f_norm = (f - f.min()) / (f.max() - f.min())\n",
    "    filtered = f_norm\n",
    "    return filtered\n",
    "\n",
    "# creating histogram for Otsu threshholding  \n",
    "def custom_histogram(image: np.ndarray, nbins: int = 256) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the histogram and corresponding bin centers of a grayscale image,\n",
    "    replicating the behavior of skimage.exposure.histogram, including normalization\n",
    "    to the [0, 255] range. This ensures consistent behavior with Otsu implementations\n",
    "    that assume 8-bit images.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image as a 2D array of grayscale values.\n",
    "        nbins (int): Number of bins for the histogram (default: 256).\n",
    "\n",
    "    Returns:\n",
    "        hist (np.ndarray): Array of histogram frequencies for each bin.\n",
    "        bin_centers (np.ndarray): Array of bin center values.\n",
    "    \"\"\"\n",
    "    # Determine the minimum and maximum pixel intensity in the image\n",
    "    img_min, img_max = image.min(), image.max()\n",
    "\n",
    "    # Normalize the image intensities to the range [0, 255], as in skimage\n",
    "    image_scaled = (image - img_min) / (img_max - img_min) * 255\n",
    "\n",
    "    # Compute the histogram of the scaled image within [0, 255]\n",
    "    hist, bin_edges = np.histogram(\n",
    "        image_scaled.ravel(),\n",
    "        bins=nbins,\n",
    "        range=(0, 255)\n",
    "    )\n",
    "\n",
    "    # Compute bin centers as the average of adjacent bin edges\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    return hist, bin_centers\n",
    "\n",
    "# Otsu thresholding\n",
    "def apply_global_otsu(image: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the global Otsu threshold of an input grayscale image in a way that matches\n",
    "    the behavior of skimage.filters.threshold_otsu, including histogram scaling and\n",
    "    threshold rescaling back to the original intensity range.\n",
    "\n",
    "    This function enables nearly identical thresholding results to skimage's implementation,\n",
    "    even on images with floating-point or non-8-bit integer data.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image as a 2D array of grayscale values.\n",
    "\n",
    "    Returns:\n",
    "        threshold_original (float): Computed Otsu threshold mapped back to the original image range.\n",
    "    \"\"\"\n",
    "    # Compute histogram and bin centers consistent with skimage\n",
    "    hist, bin_centers = custom_histogram(image, nbins=256)\n",
    "    hist = hist.astype(np.float64)\n",
    "\n",
    "    # Normalize histogram to obtain probability distribution p(k)\n",
    "    p = hist / hist.sum()\n",
    "\n",
    "    # Compute cumulative sums of class probabilities ω0 and ω1\n",
    "    omega0 = np.cumsum(p)                           # Class probabilities for background\n",
    "    omega1 = np.cumsum(p[::-1])[::-1]               # Class probabilities for foreground\n",
    "\n",
    "    # Compute cumulative sums of class means μ0 and μ1\n",
    "    mu0 = np.cumsum(p * bin_centers)                # Class means for background\n",
    "    mu1 = np.cumsum((p * bin_centers)[::-1])[::-1]  # Class means for foreground\n",
    "\n",
    "    # Compute between-class variance σ_b^2 for each possible threshold\n",
    "    sigma_b_squared = (omega0[:-1] * omega1[1:] * (mu0[:-1] / omega0[:-1] - mu1[1:] / omega1[1:])**2)\n",
    "\n",
    "    # Find the threshold index t maximizing σ_b^2\n",
    "    t_idx = np.argmax(sigma_b_squared)\n",
    "    t_scaled = bin_centers[t_idx]\n",
    "\n",
    "    # Rescale threshold t back to original image intensity range\n",
    "    img_min, img_max = image.min(), image.max()\n",
    "    t_original = t_scaled / 255 * (img_max - img_min) + img_min\n",
    "\n",
    "    return (image > t_original).astype(np.uint8)\n",
    "\n",
    "# Dice score\n",
    "def dice_score(otsu_img, otsu_gt):\n",
    "\n",
    "    # control if the Pictures have the same Size\n",
    "    if len(otsu_img) != len(otsu_gt):\n",
    "       if len(otsu_img) > len(otsu_gt):\n",
    "         otsu_img = otsu_img[1:len(otsu_gt)]\n",
    "       else:\n",
    "        otsu_gt = otsu_gt[1:len(otsu_img)]\n",
    "\n",
    "\n",
    "    # defining the variables for the Dice Score equation\n",
    "    positive_overlap = 0\n",
    "    sum_img = 0\n",
    "    sum_gt = 0\n",
    "\n",
    "    for t, p in zip(otsu_img, otsu_gt):\n",
    "        if t == 1:\n",
    "            sum_img += 1\n",
    "        if p == 1:\n",
    "            sum_gt += 1\n",
    "        if t == 1 and p == 1:\n",
    "            positive_overlap += 1\n",
    "\n",
    "    if sum_img + sum_gt == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return 2 * positive_overlap / (sum_img + sum_gt)\n",
    "\n",
    "# Process single image and its groundtruth\n",
    "def process_single(img_path: Path, gt_path: Path) -> float:\n",
    "    \"\"\" \n",
    "    Reads one image and corresponding groundtruth, proccesses, segments and computes dice score for one image.\n",
    "    \"\"\"\n",
    "    # Reads image and reads, binarizes groundtruth\n",
    "    img = imread(img_path, as_gray=True)\n",
    "    img_scaled  = ((img / img.max()) * 255).astype(np.uint8)\n",
    "    gt = imread(gt_path, as_gray=True)\n",
    "    gt  = 1 - (((gt / gt.max()) * 255).astype(np.uint8) == 0)         \n",
    "    \n",
    "    # Wiener fitler, background estimation and removal\n",
    "    img_filtered = img_scaled - local_wiener_filter(img_scaled, window_size=201)\n",
    "\n",
    "    # Otsu\n",
    "    binary1 = apply_global_otsu(img_filtered)\n",
    "    \n",
    "    # Invert if necessary\n",
    "    if np.mean(binary1) > 0.5:\n",
    "        binary1 = ~binary1\n",
    "\n",
    "\n",
    "    # 5. Compute Dice score\n",
    "    return dice_score(binary1.flatten(), gt.flatten())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Mainroutine: Going through all image-gt pairs and collect all dice scores\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# data set: NIH3T3\n",
    "img_dir = Path(\"data/NIH3T3/img\")\n",
    "gt_dir  = Path(\"data/NIH3T3/gt\")\n",
    "\n",
    "dice_scores_NIH3T3 = []\n",
    "\n",
    "for img_file in sorted(img_dir.glob(\"dna-*.png\")):\n",
    "    # Extract index to read the corresponding gt\n",
    "    idx = img_file.stem.split('-')[-1]\n",
    "    gt_file = gt_dir / f\"{idx}.png\"\n",
    "\n",
    "    if not gt_file.exists():\n",
    "        print(f\" ! Kein Ground-Truth für {img_file.name} ! überspringe …\")\n",
    "        continue\n",
    "\n",
    "    score = process_single(img_file, gt_file)\n",
    "    dice_scores_NIH3T3.append(score)\n",
    "    print(f\"{img_file.name:<20} Dice = {score:.4f}\")\n",
    "\n",
    "# Vector containing all dice scores\n",
    "dice_scores_NIH3T3 = np.array(dice_scores_NIH3T3)           \n",
    "print(\"\\nDONE ⇢ Mean Dice:\", dice_scores_NIH3T3.mean())\n",
    "\n",
    "np.save('NIH3T3_wiener_dice_scores', dice_scores_NIH3T3)\n",
    "\n",
    "\n",
    "\n",
    "# data set: N2DL-HeLa\n",
    "img_dir = Path(\"data/N2DL-HeLa/img\")\n",
    "gt_dir  = Path(\"data/N2DL-HeLa/gt\")\n",
    "\n",
    "dice_scores_N2DL_HeLa = []\n",
    "\n",
    "for img_file in sorted(img_dir.glob(\"t-*.tif\")):\n",
    "    # Extract index to read the corresponding gt\n",
    "    idx = img_file.stem.split('-')[-1]\n",
    "    gt_file = gt_dir / f\"man_seg{idx}.tif\"\n",
    "\n",
    "    if not gt_file.exists():\n",
    "        print(f\" ! Kein Ground-Truth für {img_file.name} ! überspringe …\")\n",
    "        continue\n",
    "\n",
    "    score = process_single(img_file, gt_file)\n",
    "    dice_scores_N2DL_HeLa.append(score)\n",
    "    print(f\"{img_file.name:<20} Dice = {score:.4f}\")\n",
    "\n",
    "# Vector containing all dice scores\n",
    "dice_scores_N2DL_HeLa = np.array(dice_scores_N2DL_HeLa)           \n",
    "print(\"\\nDONE ⇢ Mean Dice:\", dice_scores_N2DL_HeLa.mean())\n",
    "\n",
    "np.save('N2DL-HeLa_wiener_dice_scores', dice_scores_N2DL_HeLa)\n",
    "\n",
    "\n",
    "# dataset: N2DH-GOWT1\n",
    "img_dir = Path(\"data/N2DH-GOWT1/img\")\n",
    "gt_dir  = Path(\"data/N2DH-GOWT1/gt\")\n",
    "\n",
    "dice_scores_N2DH_GOWT1 = []\n",
    "\n",
    "for img_file in sorted(img_dir.glob(\"t-*.tif\")):\n",
    "    # Extract index to read the corresponding gt\n",
    "    idx = img_file.stem.split('-')[-1]\n",
    "    gt_file = gt_dir / f\"man_seg{idx}.tif\"\n",
    "\n",
    "    if not gt_file.exists():\n",
    "        print(f\" ! Kein Ground-Truth für {img_file.name} ! überspringe …\")\n",
    "        continue\n",
    "\n",
    "    score = process_single(img_file, gt_file)\n",
    "    dice_scores_N2DH_GOWT1.append(score)\n",
    "    print(f\"{img_file.name:<20} Dice = {score:.4f}\")\n",
    "\n",
    "# Vector containing all dice scores\n",
    "dice_scores_N2DH_GOWT1 = np.array(dice_scores_N2DH_GOWT1)           \n",
    "print(\"\\nDONE ⇢ Mean Dice:\", dice_scores_N2DH_GOWT1.mean())\n",
    "\n",
    "np.save('N2DH-GOWT1_wiener_dice_scores', dice_scores_N2DH_GOWT1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
